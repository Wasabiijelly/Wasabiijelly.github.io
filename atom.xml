<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>데이터분석 &amp; 딥러닝 에 관한 얘기들을 올려놓습니다</description>
    <link>
    https://Wasabiijelly.github.io</link>
    
      
      <item>
        <title>Metagenome Project - Metadata Cleansing</title>
        
          <description>&lt;p&gt;```R&lt;/p&gt;
&lt;h2 id=&quot;set-working-env&quot;&gt;Set Working Env.&lt;/h2&gt;
&lt;p&gt;setRepositories(ind=1:8)
WD &amp;lt;- ‘/disk3/bihy/metagenomeData’
setwd(WD)&lt;/p&gt;

</description>
        
        <pubDate>Mon, 02 May 2022 22:45:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/project-Metagenome-metacleansing</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/project-Metagenome-metacleansing</guid>
      </item>
      
    
      
      <item>
        <title>Metagenome Project - intro</title>
        
          <description>&lt;h4 id=&quot;목차&quot;&gt;[목차]&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Metagenome 이란?&lt;/li&gt;
  &lt;li&gt;가설 설정&lt;/li&gt;
  &lt;li&gt;배경 지식(질병, 미생물 종)&lt;/li&gt;
  &lt;li&gt;프로젝트 과정&lt;/li&gt;
&lt;/ol&gt;

</description>
        
        <pubDate>Mon, 25 Apr 2022 23:50:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/project-Metagenome-intro</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/project-Metagenome-intro</guid>
      </item>
      
    
      
      <item>
        <title>Estimating beta in Simple Linear Regression(단순선형회귀 베타 추정)</title>
        
          <description>&lt;p&gt;앞선 포스팅에서 LSE와 이를 통한 B0, B1의 계산 공식을 설명하였다.&lt;br /&gt;
&lt;img src=&quot;assets/built/images/LinearRegression/estimatingb.jpg&quot; alt=&quot;LSE&quot; title=&quot;optional title&quot; /&gt;
위 식의 유도 과정은 아래와 같다.&lt;/p&gt;
</description>
        
        <pubDate>Sat, 26 Feb 2022 18:33:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/deeplearning-estimatingb</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/deeplearning-estimatingb</guid>
      </item>
      
    
      
      <item>
        <title>Linear Regression &amp; Least Square Estimation(최소자승법)</title>
        
          <description>&lt;h4 id=&quot;1-least-square-estimation이란&quot;&gt;1. Least Square Estimation이란?&lt;/h4&gt;
&lt;p&gt;&lt;br /&gt;
Linear Regression 모델을 만든다는 것은 데이터를 잘 설명하는 선을 만드는 것이라고 앞선 포스팅에서 말하였다. 그렇다면 아래 그림의 A, B, C 에서 어던 선이 데이터를 잘 설명하는 것일까? &lt;br /&gt;
&lt;img src=&quot;assets/built/images/LinearRegression/lse1.png&quot; alt=&quot;LSE&quot; title=&quot;optional title&quot; /&gt;
인간으로 봤을 때, 당연히 B라고 할 수 있다. 하지만, 컴퓨터의 입장에서 데이터를 잘 &lt;strong&gt;설명&lt;/strong&gt; 한다는 기준은 어떻게 만드는 걸까? 이 때 &lt;strong&gt;Least Square Estimation(LSE)&lt;/strong&gt; 개념이 나온다. &lt;br /&gt;
직역하자면 ‘&lt;strong&gt;최소 제곱법&lt;/strong&gt;‘인데, 무엇이 최소 제곱이라는 것일까?&lt;br /&gt;
&lt;img src=&quot;assets/built/images/LinearRegression/lse2.png&quot; alt=&quot;LSE&quot; title=&quot;optional title&quot; /&gt;
위의 그림에서 &lt;strong&gt;빨간 선(Residual)을 제곱한 값이 최소인 직선&lt;/strong&gt;을 데이터를 제일 잘 설명하는 직선이라고 한다. 다시 말해, &lt;strong&gt;관측값(데이터)과 예측값(직선 위의 값) 차이의 제곱값을 최소화&lt;/strong&gt;하는 파라미터 (B0, B1)을 추정하는 방법을 Least Square Estimation이라고 한다.&lt;/p&gt;
&lt;h4 id=&quot;2-lse가-최선일까&quot;&gt;2. LSE가 최선일까?&lt;/h4&gt;
&lt;p&gt;&lt;br /&gt;
이 때, LSE로 추정한 직선 말고 &lt;strong&gt;다른 방법&lt;/strong&gt;으로 직선을 추정할 수 있지 않을까? 하는 의문이 들 수 있다. 하지만, 앞 포스팅에서 말한 4가지 가정(&lt;strong&gt;선형성, 등분산성, 정규성, 독립성&lt;/strong&gt;)을 만족하는 데이터라면 가우스-마코브 이론(Gauss Marcov Theorem)에 의해 BLUE(Best Linear Unbiased Estimator)이라 할 수 있다. 쉽게 말해 가정만 지켜진다면 &lt;strong&gt;LSE로 추정하는 직선이 데이터를 최적으로 설명할 수 있는 직선&lt;/strong&gt;이라는 의미이다.&lt;/p&gt;
&lt;h4 id=&quot;3-lse의-계산&quot;&gt;3. LSE의 계산&lt;/h4&gt;
&lt;p&gt;&lt;br /&gt;
LSE로 최적의 직선을 만드는 B0, B1 값을 알아낼 수 있다는 것을 알았다. LSE를 이용한 B0, B1의 추정값은 다음과 같다.
&lt;img src=&quot;assets/built/images/LinearRegression/estimatingb.jpg&quot; alt=&quot;LSE&quot; title=&quot;optional title&quot; /&gt;
여기서 B1의 값은 최종적으로 (x,y의 공분산)/(x의 분산)이 됨을 알 수 있다. 위 식의 유도과정은 다음 포스팅에서 하겠다.&lt;/p&gt;
</description>
        
        <pubDate>Sat, 26 Feb 2022 15:02:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/deeplearning-LSE</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/deeplearning-LSE</guid>
      </item>
      
    
      
      <item>
        <title>Linear Regression-basic</title>
        
          <description>&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Linear Regression은 다음과 같은 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./deeplearning-LR&quot;&gt;ML 강좌(1) - LR 기본&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./deeplearning-LSE&quot;&gt;ML 강좌(2) - LSE 제어문&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;linear-regression-선형-회귀-분석&quot;&gt;Linear Regression (선형 회귀 분석)&lt;/h1&gt;

</description>
        
        <pubDate>Wed, 23 Feb 2022 20:25:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/deeplearning-LR</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/deeplearning-LR</guid>
      </item>
      
    
      
      <item>
        <title>데이터 분석 이론</title>
        
          <description>&lt;h2 id=&quot;이-글은-dataanalysis-tag-test-글입니다&quot;&gt;이 글은 dataAnalysis tag test 글입니다.&lt;/h2&gt;

</description>
        
        <pubDate>Tue, 22 Feb 2022 12:37:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/dataAnalysis-basic</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/dataAnalysis-basic</guid>
      </item>
      
    
      
      <item>
        <title>Deep Learning 이론</title>
        
          <description>&lt;h2 id=&quot;이-글은-tag-test-글입니다&quot;&gt;이 글은 tag test 글입니다.&lt;/h2&gt;

</description>
        
        <pubDate>Sat, 22 Jan 2022 17:37:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/deeplearning-basic</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/deeplearning-basic</guid>
      </item>
      
    
      
      <item>
        <title>이야기</title>
        
          <description>&lt;h2 id=&quot;이-글은-story-tag-test-글입니다&quot;&gt;이 글은 story tag test 글입니다.&lt;/h2&gt;

</description>
        
        <pubDate>Sat, 22 Jan 2022 11:37:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/dataAnalysis_basic</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/dataAnalysis_basic</guid>
      </item>
      
    
      
      <item>
        <title>Gettysburg Address</title>
        
          <description>&lt;p&gt;Fourscore and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.&lt;/p&gt;

</description>
        
        <pubDate>Thu, 19 Nov 1863 19:18:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/gettysburg-address</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/gettysburg-address</guid>
      </item>
      
    
      
      <item>
        <title>Probability &amp; Statistics 이론(1) - 사건과 확률</title>
        
          <description>&lt;p&gt;이 글은 probAndStat tag test 글입니다.&lt;/p&gt;
</description>
        
        <pubDate>Sat, 03 Jan 1863 02:37:00 +0900</pubDate>
        <link>
        https://Wasabiijelly.github.io/probAndStat-basic</link>
        <guid isPermaLink="true">https://Wasabiijelly.github.io/probAndStat-basic</guid>
      </item>
      
    
  </channel>
</rss>
